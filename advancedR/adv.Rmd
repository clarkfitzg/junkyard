Studying Hadley Wickham's Advanced R book.

```{r, echo=FALSE}
a = 1:10
typeof(a)
class(a)
attributes(a)
attributes(a) = list(style='awesome', foo='bar')
is.vector(a)
str(a)
attr(a, 'foo') = 1:5
attr(a, 'foo') 
```
So we can set arbitrary attributes on vectors.

What's the difference between `typeof` and `class`?
I think typeof is the underlying storage.

```{r, echo=FALSE}
b = c(1, 2, NA_character_)
b
```
Coerces to character. Fair enough

```{r, echo=FALSE}
     is.a.r <- function(x) c(is.atomic(x), is.recursive(x))

x = c(a=1, b=12)
class(x)
x
attributes(x)
str(x)
     is.a.r(c(a = 1, b = 3)) # TRUE FALSE
     is.a.r(list())          # FALSE TRUE - a list is a list
     is.a.r(list(2))         # FALSE TRUE
     is.a.r(lm)              # FALSE TRUE
     is.a.r(y ~ x)           # FALSE TRUE
     is.a.r(expression(x+1)) # FALSE TRUE (nowadays)

f1 = y ~ x
str(f1)
is.list(f1)
class(f1)
```
#curious
The formula is not a list but is still recursive. Why?
How is a formula stored internally?

We see that names are accessible from attributes.


```{r, echo=FALSE}

l = c(TRUE, FALSE)
typeof(l)
# Coercion
l2 = c(l, 2)
l2
l3 = c(l2, 1.3)
l3
l4 = c(l3, 'abc')
l4

a = NA
typeof(a)
```

The order of coercion: logical, integer, double, string

Hence NA is logical by default- it just gets coerced into whatever it
should actually be. That's convenient. p. 19

```{r, echo=FALSE}
x = list(list(1, 2), list(3, 4))
str(x)
y = list(list(1, 2), c(3, 4))
str(y)
y[[2]]
z = c(list(1, list(72)), list(3, 4))
str(z)
a = list(list(1, 2), 3)
a
unlist(a)
unlist(a, recursive=F)
```

So it looks like `c` flattened the list while `list` preserves the
structure.

Also, unlist is recursive by default.

```{r, echo=FALSE}
a = list(x = 1:10, y=list(a = 1, b = 2))
a
str(a)
b = structure(a, foo='bar')
attributes(b)
```
structure to add new attributes

Names, dim, and class are the most important attributes

```{r, echo=FALSE}
x = c(a=1, b=2)
names(x) = 'hello'
x
str(x)
names(x) = NULL
unname(x)
f = function(x){
    setNames(x, c('a', 'b'))
}
f(1:4)
```

So names doesn't recycle. Just sets the first k if there are too few
specified.

```{r, echo=FALSE}
x = factor(c('a', 'b', 'a'))
y = factor(c('a', 'b', 'a'))
x
#x[2] = 'd'
#y = c(factor('a'), factor('b'))
z = c(x, y)
z
levels(x) = c('b', 'a')
x
rev(1:5)
# A nice way to get a mapping of letters to integers
rev(factor(letters))
factor(letters, levels = rev(letters))
# This changes the encoding so that z is 1 and a is 26.

l = factor(letters)
l
levels(l) = rev(letters)
# Updating levels later changes:
#       oldlevel --> newlevel
```

Don't try to combine factors with c- doesn't work.
Modifying levels changes how they are encoded.

```{r, echo=FALSE}
x = structure(1:4, foo='bar')
x
structure(1:4, foo='bar')
```
The above seems to print just fine. Ex 2.2.2.1


```{r, echo=FALSE}
a = 1:12
a
dim(a)
dim(a) = c(2, 6)
class(a)
typeof(a) # Underlying storage
dim(a) = c(2, 2, 3)
class(a)
dim(a)
dimnames(a) = list(c('r1', 'r2'), c('c1', 'c2'), c('f1', 'f2', 'f3'))
a
```

Numpy arrays have much in common with R vectors. But can Numpy arrays store
various objects? That is, be recursive? Yes.


```{r, echo=FALSE}
x = 1:12
x = as.array(x, dim=c(2, 3, 2)) # Why isn't this working?
array(1:12, dim=c(2, 3, 2))
x
y = array(1:12, dim=c(2, 6))
y
class(y) # it's a matrix
as.matrix(1:12, dim=c(2, 6))
```

Was wondering why this as.matrix didn't work as expected. Looking at the
code for `as.matrix.default` I see why. Better to use `matrix` and then
as.matrix for dataframes.

```{r, echo=FALSE}
a = data.frame(x=1:2, y=3:4)
a
as.matrix(a)
matrix(a)
b = as.vector(a)
class(b) # Still a dataframe. Strange
```

Did not realize that one could set the dim for a list. Not commonly done.

```{r, echo=FALSE}
x = list(a=1, b='cats', c=1:4, d=TRUE)
x
dim(x) = c(2, 2)
x[[1, 2]]
names(x)
# Seems that it lost the names
is.matrix(x) # TRUE - kind of surprising
dim(1:3)
```

So is.matrix just checks if it has the dim attribute set? No since a data
frame is not a matrix. So that's not particularly consistent.

```{r, echo=FALSE}
a = data.frame(x=1:2, y=c('one', 'two'), stringsAsFactors=FALSE)
a
sapply(a, class)
is.matrix(a)
dim(a)
str(a)
class(a)
typeof(a)

library(plyr)
b = data.frame(x = 3:4)
a
b
rbind(a['x'], b)

# Lets try error handling
binder = function(x, y){
    # rbind x and y, with error handling
    tryCatch(rbind(x, y), error = function(e) 'Kaboom!', 
             finally = print('its all over'))
}
d = binder(a, b)
d
e = binder(a['x'], b)
e

f = plyr::rbind.fill(a, b)
is.na(f[3, 4])  # False
is.null(f[3, 4])  # True
```

Good that rbind throws an error if the names do not match.
The body of is.data.frame is quite simple.


```{r, echo=FALSE}
crazy = data.frame(x=1:3)
crazy$y = matrix(1:6, nrow=3)
crazy
dim(crazy)
```
Just because you can use arrays and such as columns for dataframes doesn't
mean that you should.


```{r, echo=FALSE}
a = data.frame(x=1:2, y=c('a','b'))
as.matrix(a)
b = data.frame(x=NULL, y=NULL)
dim(b)
b
b[1,1]
rbind(a, b)
cbind(a, b)
```

as.matrix on dataframe coerces to most generic type.
Yes, you can make a data frame with no rows / columns
rbind works but cbind does not.

```{r, echo=FALSE}
x = 1:10
x[-c(4, 6, 3)]
x[c(TRUE, FALSE)] 
# Recycles, picking out the odd indices. Numpy doesn't do this.
x[]
y = setNames(x, letters[1:10]) # useful just before function return
a = y[c('a', 'bc')]
is.na(a[2])
x[13:16]
```

Doesn't raise an error if you try to access names that don't exist.
Is the same true for a list? Yes. Most Python will throw a KeyError

```{r, echo=FALSE}
a = list(x=1, y=2)
a[['abcx']]
```

Trying some nonlinear minimization:

```{r, echo=FALSE}
f1 = function(p){
    out = sum(p)
    return(out)
}

r1 = nlm(f1, p=c(1, 1, 2))

# Manually set the gradient
f2 = function(p){
    out = sum(p ** 2)
    attr(out, 'gradient') = 2 * p
    return(out)
}


r2 = nlm(f2, p=c(1, 1, 2))

# No gradient
f3 = function(p){
    out = sum(p ** 2)
    return(out)
}

r3 = nlm(f3, p=c(1, 1, 2))

f2(c(1, 1, 2))
```

```{r, echo=FALSE}
a = list(alpha=10, bravo=20)
a[[1]]
a[1:2]
```

Arrays in R are in column major order. In Python they are in row major
order.
```{r, echo=FALSE}
a = matrix(1:10, nrow=2)
a

colnames(a) = letters[1:5]
b = a[1, ]
dim(b)
```

```{r, echo=FALSE}
a = matrix(1:4, nrow=2)
b = matrix(c(1, 1, 2, 2), nrow=2)
a[b]
a[c(1, 1, 2, 2)]
```

So subsetting a matrix with another matrix uses the rows of a matrix to pick out the indices.
Does this result in fast subsetting when combined with outer?

Suppose I want to extract the diagonals of a matrix. There are three ways
to do this.

```{r, echo=FALSE}
library(microbenchmark)

n = 1000
# Big square matrix
x = matrix(1:(n**2), nrow=n)

# Use built in diag function
d1 = diag(x)
microbenchmark(diag(x))

ds = matrix(rep(1:n, 2), ncol=2)
d2 = x[ds]
microbenchmark(ds[d2])

d3 = x[matrix(rep(1:nrow(x), 2), ncol=2)]
microbenchmark(x[matrix(rep(1:nrow(x), 2), ncol=2)])
```

The subsetting is 3 orders of magnitudes faster than diag. Surprising. What
if I don't have the matrix built ahead of time? Still 2 orders of magnitude
faster. 

```{r, echo=FALSE}
loopdiag = function(x) {
    n = nrow(x)
    out = rep(NA_integer_, n)
    for (i in 1:n) {
        out[i] = x[i, i]
    }
    out
}
d4 = loopdiag(x)
microbenchmark(loopdiag(x))
```

The loop version runs in about the same time as regular diag- demonstrating
the effectiveness of vectorization in R. Makes sense because each iteration
of the loop is doing at least two R function calls.

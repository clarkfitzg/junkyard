---
title: "Stats 206 Homework 2"
author: "Clark Fitzgerald"
date: "October 16, 2014"
output: pdf_document
---


## 1a

```{r, echo=FALSE}
setwd('~/junkyard/STA206/hw2')
women = read.table('muscle.txt')
names(women) = c('muscle', 'age')
```

The histograms of muscle and age are unsurprising. The ranges are as expected. Age appears to be roughly uniform and muscle has a bell shape.

```{r, echo=FALSE}
par(mfrow=c(1, 2))
hist(women$age, xlab = 'age', main = '')
hist(women$muscle, xlab = 'muscle', main = '')
```

The relation between age and muscle appears to be linear, and it looks like muscle
mass decreases with age.

```{r, echo=FALSE}
scatter = function(){
  plot(women$age, women$muscle, xlab = 'age', ylab = 'muscle')
}

scatter()
```

## 1b

After fitting the linear model we extract regression coefficients with 
their standard errors, the mean squared
error (MSE), and its degrees of freedom.

Regression coefficients:
```{r}
simple = lm(muscle ~ age, data=women)
b0 = simple$coefficients[1]
b1 = simple$coefficients[2]
c(b0, b1)
```

Standard errors for regression coefficients:
```{r}
ss = summary(simple)
ss$coefficients[, 'Std. Error']
```

The MSE and its degrees of freedom are:
```{r}
a = anova(simple)
mse = a['Residuals', 'Mean Sq']
df = a['Residuals', 'Df']

c(mse, df)
```

## 1c

The fitted regression line is:
```{r}
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
        simple$coefficients['age'])
```

```{r, echo=FALSE}
scatter()
abline(simple)
```
It looks like the linear regression is a good fit.

## 1d

The fitted values for the 6th and 16th cases are:
```{r}
simple$fitted.values[c(6, 16)]
```

The residuals for the 6th and 16th cases are:
```{r}
simple$residuals[c(6, 16)]
```

## 1e
```{r, echo=FALSE}
par(mfrow=c(1, 2))
plot.lm(simple, which=1)
plot.lm(simple, which=2)
```

Using linear algebra notation,
the simple linear regression model with Normal errors assumes

- $y = X \beta + \epsilon$ The response is a linear function of the predictors.

- $\epsilon \sim Normal(0, \sigma^2 I_n)$ The error terms are normally distributed and uncorrelated.

The graphs support the assumptions of the model.

## 1f

A 99 percent confidence interval for the estimated regression intercept is:
```{r, echo=FALSE}
confint(simple, '(Intercept)', 0.99)
```
We are 99 percent confident that the the true parameter lies within this
interval.

## 1g

We test at level 0.01 to see if there is a negative linear association
between muscle mass and age. $H_0$ is $\beta_1 = 0$ and $H_1$ is the
left sided alternative hypothesis $\beta_1 < 0$. 

The test statistic is 
$T^* = \frac{\hat(\beta_1) - 0}{se(\hat(\beta_1))} \sim t(n - 2)$.

The decision rule is to reject $H_0$ if $T^* < t(0.99, n - 2)$.

```{r, echo=FALSE}
alpha = 0.01
t99 = qt(alpha, df=df)
tstar = b1 / ss$coefficients[2, 'Std. Error']

sprintf('If %.3f is less than %.3f we reject H0', tstar, t99)
```

We reject the null hypothesis and conclude that there is a significant 
negative linear association between amount of muscle mass and age.

## 1h

A 95% prediction interval for the muscle mass for women of age 60 is:
```{r}
predict(simple, data.frame(age=60), interval='prediction', level=0.95)
```
The fit is the expected value. We expect 95% of new observations to fall 
between the lower and upper bounds.


## 1i

The limits of a the 95% simultaneous confidence bands for the regression
line at $x_h = 60$ are:
```{r}

p60 = predict(simple, data.frame(age=60), se.fit=TRUE, 
    interval='prediction', level=0.95)

# Actual fitted value
fit60 = p60$fit[1] 
se60 = p60$se.fit

# Working-Hotelling multiplier
W = sqrt(2 * qf(0.95, 2, df)) 

c(fit60 - W * se60, fit60 + W * se60)
```

## 1j

The ANOVA table for this data is:
```{r, echo=FALSE}
a
```

We use an F test at level 0.01 to see if there is a linear association
between muscle mass and age. $H_0$ is $\beta_1 = 0$ and $H_1$ is the
two sided alternative hypothesis $\beta_1 \neq 0$. 

The test statistic is 
$F^* = \frac{\hat(\beta_1) - 0}{se(\hat(\beta_1))} ~ t(n - 2)$.

The decision rule is to reject $H_0$ if $F^* > F(0.99; 1, n - 2)$.

```{r}
f99 = qf(0.99, 1, n-2)
msr = sum(simple$residuals ** 2) / n
fstar = msr / mse

sprintf('If %.3f is less than %.3f we reject H0', fstar, f99)
```

We reject the null hypothesis and conclude that there is a significant 
linear association between amount of muscle mass and age.

## 1k

The proportion of total variation in muscle mass explained by age is $R^2$:
```{r}
summary(simple)$r.squared
```

The correlation between muscle mass and age is:
```{r}
cor(women$muscle, women$age)
```

## 1l

We fit the model using the log of age.

```{r, echo=FALSE}
logsimple = lm(muscle ~ log(age), data=women)
summary(logsimple)
plot(log(women$age), women$muscle)
abline(logsimple)
```

This model has the corresponding residual plots:

```{r, echo=FALSE}
par(mfrow=c(2, 2))
plot(logsimple)
```

The fit looks similar to the first model.

## 1m

We plot the Box-Cox power transformation.

```{r, echo=FALSE}
library(MASS)
boxcox(simple)
```

This suggests that a value of $\lambda = 1$ is appropriate. In other words, no
transformation is required.

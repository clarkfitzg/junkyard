---
title: "Stats 206 Homework 2"
author: "Clark Fitzgerald"
date: "October 16, 2014"
output: pdf_document
---


## 1a

```{r, echo=FALSE}
setwd('~/junkyard/STA206/hw2')
women = read.table('muscle.txt')
names(women) = c('muscle', 'age')
```

The histograms of muscle and age are unsurprising. The ranges are as expected. Age appears to be roughly uniform and muscle has a bell shape.

```{r, echo=FALSE}
par(mfrow=c(1, 2))
hist(women$age, xlab = 'age', main = '')
hist(women$muscle, xlab = 'muscle', main = '')
```

The relation between age and muscle appears to be linear, and it looks like muscle
mass decreases with age.

```{r, echo=FALSE}
scatter = function(){
  plot(women$age, women$muscle, xlab = 'age', ylab = 'muscle')
}

scatter()
```

## 1b

After fitting the linear model we extract regression coefficients with 
their standard errors, the mean squared
error (MSE), and its degrees of freedom.

Regression coefficients:
```{r, echo=FALSE}
simple = lm(muscle ~ age, data=women)
b0 = simple$coefficients[1]
b1 = simple$coefficients[2]
print(b0, b1)
```

Standard errors for regression coefficients:
```{r, echo=FALSE}
ss = summary(simple)
ss$coefficients[, 'Std. Error']
```

The MSE and its degrees of freedom are:
```{r, echo=FALSE}
a = anova(simple)
a['Residuals', c('Df', 'Mean Sq')]
```

## 1c

The fitted regression line is:
```{r, echo=FALSE}
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
        simple$coefficients['age'])
```

```{r, echo=FALSE}
scatter()
abline(simple)
```
It looks like the linear regression is a good fit.

## 1d

The fitted values for the 6th and 16th cases are:
```{r, echo=FALSE}
simple$fitted.values[c(6, 16)]
```

The residuals for the 6th and 16th cases are:
```{r, echo=FALSE}
simple$residuals[c(6, 16)]
```

## 1e
```{r, echo=FALSE}
par(mfrow=c(1, 2))
plot.lm(simple, which=1)
plot.lm(simple, which=2)
```

Using linear algebra notation,
the simple linear regression model with Normal errors assumes
- $y = X \beta + \epsilon$ The response is a linear function of the predictors.
- $\epsilon ~ $ Normal$(0, \sigma^2 I_n)$ The error terms are normally distributed and uncorrelated.

#TODO - interpret plot

## 1f

A 99 percent confidence interval for the estimated regression intercept is:
```{r, echo=FALSE}
confint(simple, '(Intercept)', 0.99)
```
We are 99 percent confident that the the true parameter lies within this
interval.

## 1g

We test at level 0.01 to see if there is a negative linear association
between muscle mass and age. $H_0$ is $\beta_1 \geq 0$ and $H_1$ is the
left sided alternative hypothesis $\beta_1 < 0$. 

The test statistic is 
$T^* = \frac{\hat(\beta_1) - 0}{se(\hat(\beta_1))} ~ t(n - 2)$.

The decision rule is to reject $H_0$ if $T^* < t(0.99, n - 2)$.

```{r, echo=FALSE}
alpha = 0.01
degfree = anova(simple)['Residuals', 'Df']
t99 = qt(alpha, df=degfree)
tstar = b1 / ss$coefficients[2, 'Std. Error']

sprintf('If %.3f is less than %.3f we reject H0', tstar, t99)
```

We reject the null hypothesis and conclude that there is a significant 
negative linear association between amount of muscle mass and age.

## 1h

A 95% prediction interval for the muscle mass for women of age 60 is:
```{r, echo=FALSE}
predict(simple, data.frame(age=60), interval='prediction', level=0.95)
```
We would expect 95% of new observations to fall between the lower and upper
bounds.


## 1

```{r, echo=FALSE}
```

## 1

```{r, echo=FALSE}
```

## 1

```{r, echo=FALSE}
```

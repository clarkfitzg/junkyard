class(train$Survived) <- "logical"
# Average out the ages to remove NA values
CleanAge <- function(data){
m <- mean(data$Age, na.rm = TRUE)
data$Age[is.na(data$Age)] <<- m
}
l_ply(list(test, train), CleanAge)
?assign
?replace
CleanAge(test)
CleanAge <- function(x){
m <- mean(x$Age, na.rm = TRUE)
x$Age[is.na(x$Age)] <<- m
}
CleanAge(test)
?assign
colnames(train)
?environment
.GlobalEnv
.GlobalEnv()
globalenv()
?get
get(test)
get("test")
CleanAge <- function(string){
y <- get(string, envir = .GlobalEnv)
m <- mean(y$Age, na.rm = TRUE)
y$Age[is.na(y$Age)] <- m
assign(string, y, envir = .GlobalEnv)
}
CleanAge(train)
CleanAge("train")
train$Age
rm(list = ls())
# This script explores Kaggle's Titanic data
train <- read.csv("~/data/titanic/train.csv")
test <- read.csv("~/data/titanic/test.csv")
# Let's try a Support Vector Machine.
library(e1071)
library(plyr)
# We'll just use the data that we can easily use
# Here is the formula defined:
fm1 <- formula(Survived ~ Pclass + Sex + Age + Parch + Fare)
# Wrong type of dependent variable?
class(train$Survived) <- "logical"
# Average out the ages to remove NA values
CleanAge <- function(x){
m <- mean(x$Age, na.rm = TRUE)
x$Age[is.na(x$Age)] <<- m
}
CleanAge <- function(string){
y <- get(string, envir = .GlobalEnv)
m <- mean(y$Age, na.rm = TRUE)
y$Age[is.na(y$Age)] <- m
assign(string, y, envir = .GlobalEnv)
}
l_ply(c("test", "train"), CleanAge)
test$Age
tune.mod1 <- tune(svm, fm1, data = train
, ranges = list(gamma = 2^(-1:1), cost = 2^(2:4))
, tunecontrol = tune.control(sampling = "cross", cross = 5)
, type = "C")
output <- predict(tune.mod1$best.model, test)
head(output)
sum(output)
sum(as.logical(output))
?write.csv
head(as.integer(output))
output <- !(as.logical(output))
head(output)
output <- predict(tune.mod1$best.model, test)
output <- as.integer((as.logical(output)))
head(output)
write.csv(output, "~/data/titanic/svm0.csv")
write.csv(output, "~/data/titanic/svm0.csv",row.names = FALSE, col.names = FALSE)
write.csv(output, "~/data/titanic/svm0.csv",row.names = FALSE)
View(test)
output <- colbind(test$PassengerId, output)
output <- col.bind(test$PassengerId, output)
output <- cbind(test$PassengerId, output)
output <- predict(tune.mod1$best.model, test)
output <- as.integer((as.logical(output)))
head(row.names(output))
head(output)
head(names(output))
head(test)
a <- as.character(test)
?ddply
?daply
sum(daply(test, is.na()))
sum(daply(test, is.na))
head(output)
output
head(Pclass)
head(test$Pclass)
unique(test$Pclass)
unique(test$Sex)
unique(test$Parch)
unique(test$Fare)
test$Fare[is.na(test$Fare)] <- mean(test$Fare)
output <- predict(tune.mod1$best.model, test)
output <- predict(tune.mod1$best.model, test)
length(output)
class(test$Fare)
sum(is.na(test$Fare))
test$Fare[is.na(test$Fare)] <- mean(test$Fare, na.rm)
test$Fare[is.na(test$Fare)] <- mean(test$Fare, na.rm = TRUE)
output <- predict(tune.mod1$best.model, test)
output <- as.integer((as.logical(output)))
output <- cbind(test$PassengerId, output)
head(output)
colnames(output) <- c("PassengerId", "Survived")
write.csv(output, "~/data/titanic/svm0.csv",row.names = FALSE, col.names = TRUE)
head(output)
install.packages("RCurl")
install.packages("twitteR")
library(twitteR)
source('~/.active-rstudio-document')
install.packages("devtools")
library(devtools)
x <- unclass(lsf.str(envir = asNamespace("stats"), all = T))
head(x)
?lsf.str
y <- ls.str(globalenv)
y <- ls.str()
y
sample(x, 20)
library(plyr)
y <- ls.str()
y
?lp
install.packages("Rglpk")
library(Rglpk)
?Rglpk
?Rglpk_solve_LP
obj <- c(1, 1)
obj <- c(2, 4, 3)
mat <- matrix(c(3, 2, 1, 4, 1, 3, 2, 2, 2), nrow = 3)
dir <- c("<=", "<=", "<=")
rhs <- c(60, 40, 80)
max <- TRUE
Rglpk_solve_LP(obj, mat, dir, rhs, max = max)
Rglpk_solve_LP(obj, mat, dir, rhs, max = max, verbose=TRUE)
odds = 0.495
?sample
sample(c(0, 1), n, replace=TRUE, prob=c(0.5 + house_dec, 0.5 - house_dec))
source('~/.active-rstudio-document')
sample(c(0, 1), n, replace=TRUE, prob=c(0.5 + house_dec, 0.5 - house_dec))
x = sample(c(0, 1), n, replace=TRUE, prob=c(0.5 + house_dec, 0.5 - house_dec))
sum(x)
source('~/.active-rstudio-document')
Experiment()
Experiment()
Experiment()
Experiment()
?repeat
asd
?replicate
source('~/dropbox/python/learn/blackjack.R')
hist(outcome)
source('~/dropbox/python/learn/blackjack.R')
install.packages('ggplot2')
source('~/dropbox/python/learn/blackjack.R')
?qplot
qplot(outcome)
?print
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
sum(outcome < 100) / length(outcome)
sum(outcome < -100) / length(outcome)
sum(outcome > 100) / length(outcome)
sum(outcome >= 100) / length(outcome)
mean(outcome)
# House edge: The ratio of the expected player loss to the initial wager.
house_edge_percent <- 0.5
house_edge <- house_edge_percent / 100
house_edge
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
odds
sum(odds)
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
y <- seq(-pi, pi, 50)
y <- seq(-pi, pi, length=50)
x <- y
?outer
f = outer(x,y, function(x,y) cos(y)/(1+x^2))
?contour
contour(x,y,f)
contour(x,y,f, nlevels=45, add=T)
fa = (f-t(f))/2
?t
image(x,y,fa)
persp(x,y,fa)
persp(x,y,fa, theta = 30, phi=20)
?fix
fix(x)
test = function(x){}
test = function(x){
print('hey there')
sin(x) + 291
}
test
fix(test)
# This script creates plots illustrating the curse of dimensionality
# Choose points, randomly distributed
n <- 3000  # number of points
p <- 50  # number of dimensions
x <- matrix(runif(n*p), ncol=p)
Fringe <- function(z){
# Determine if z lies within 0.05 distance from the boundary
# z is a vector of length p
any(abs(z - 0.5) > 0.45)
}
result <- apply(x, 1, Fringe)
plot(x[,1:2])
points(x[,1][result], x[,2][result], col='red')
source('~/dropbox/python/learn/stat-learning/ch2/notes/dimension.R')
plot(x[,1:2])
points(x[,1][result], x[,2][result], col='red')
library(MASS)
library(ISLR)
attach(Boston)
lm.fit = lm(medv ~ lstat)
plot(lstat,medv)
abline(lm.fit)
abline(lm.fit, lwd=3)
abline(lm.fit, lwd=3, col='red')
plot(lstat,medv,col='red')
plot(lstat,medv,pch=20)
plot(lstat,medv,pch='+')
plot(1:20, 1:20, pch=1:20)
?rstudent
plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
?hatvalues
plot(hatvalues(lm.fit))
?which.max
which.max(hatvalues(lm.fit))
str(lm.fit)
?lm.fit
lm.fit
medv[375]
lstat[375]
plot(lstat, medv)
points(13.8, 27.97, cex=2, col='red')
points(37.97, 13.8, cex=2, col='red', pch=20)
install.packages('knirt')
install.packages('knitr')
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00225/Indian%20Liver%20Patient%20Dataset%20(ILPD).csv'
a <- read.csv(url)
a <- list(cat=1, dog=2)
a
names(a)
names(a) = c('toad', 'frog')
names(a)
mean
knn
kmeans
?classe
?class
x <- 10
x
class(x)
class(x) <- 'funstuff'
class(x)
plot.funstuff <- function(x) hist(1:10)
plot.funstuff(x)
plot(x)
plot(x)
mean(x)
print.funstuff <- function(x) print('rock and roll dude')
print(x)
x
x + 5
x > 10
setwd('~/junkyard/STA206/hw2')
women = read.table('muscle.txt')
names(women) = c('age', 'muscle')
library(ggplot2)
?qplot
qplot(women$muscle)
par(mfrow=2)
hist(women$age, main = 'age')
hist(women$muscle, main = 'muscle')
par(mfrow=c(2, 1))
hist(women$age, main = 'age')
hist(women$muscle, main = 'muscle')
par(mfrow=c(1, 2))
hist(women$age, main = 'age')
hist(women$muscle, main = 'muscle')
?hist
par(mfrow=c(1, 2))
hist(women$age, xlab = 'age')
hist(women$muscle, xlab = 'muscle')
par(mfrow=c(1, 2))
hist(women$age, main = 'age', xlab='')
hist(women$muscle, main = 'muscle', xlab='')
?hist
par(mfrow=c(1, 2))
hist(women$age, xlab = 'age', main = '')
hist(women$muscle, xlab = 'muscle', main = '')
max(women)
source('~/.active-rstudio-document', echo=TRUE)
plot(women$age, women$muscle)
?plot
plot(women$age, women$muscle, xlab = 'age', ylab = 'muscle')
?par
simple = lm(muscle ~ age, data=women)
simple
summary(simple)
anova(simple)
coef(simple)
summary(simple)
anova(simple)
anova(women)
?sprintf
sprintf('%.3f and then', pi)
coef(simple)
simple = lm(muscle ~ age, data=women)
coef(simple)
summary(simple)
str(simple)
str(simple)
s = summary(simple)
s
str(s)
simple$coefficients
simple_summary = summary(simple)
simple_summary$coefficients[, 'Std. Error']
a = anova(simple)
a['Residuals', c('Df', 'Mean Sq')]
library(plyr)
?splat
sprintf('% and %', 1 2)
sprintf('% and %', 1, 2)
sprintf('%f and %f', 1, 2)
sprintf('%f and %f', c(1, 2))
splat(sprintf)('%f and %f', c(1, 2))
a
simple$coefficients
simple$coefficients[0]
simple$coefficients[1]
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
simple$coefficients$age)
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
simple$coefficients['age']
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
simple$coefficients['age'])
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
simple$coefficients['age'])
simple$coefficients['(Intercept)']
scatter()
abline(simple)
scatter = function(){
plot(women$age, women$muscle, xlab = 'age', ylab = 'muscle')
}
scatter()
scatter()
abline(simple)
simple$fitted.values[c(6, 16)]
simple$residuals[c(6, 16)]
plot.lm
plot(simple)
plot.lm(simple, which = 1)
plot.lm(simple, which = c(1, 2))
plot.lm(simple, which = c(1, 2))
plot.lm(simple, which = 2)
par(mfrow=c(1, 2))
plot.lm(simple, which=1)
plot.lm(simple, which=2)
hist(simple$residuals)
par(mfrow=c(1, 2))
plot.lm(simple, which=1)
plot.lm(simple, which=2)
plot(lm(1:99 ~ 1:99))
plot(lm(y ~ x, data=data.frame(1:99)))
df = data.frame(y=1:99, x=1:99 + rchisq(99, df=2))
plot.lm(df)
plot(lm(y ~ x, df))
plot.lm(df, which=2)
plot(lm(y ~ x, df), which=2)
hist(rchisq(99, 2))
qqplot(3 * rnorm(100))
?qqplot
qqnorm(3 * rnorm(100))
qqnorm(1.5 * rnorm(100))
par(mfrow=c(1,1))
qqnorm(1.5 * rnorm(100))
qqnorm(2 * rnorm(100))
qqline()
qqnorm(2 * rnorm(100))
qqnorm(chisq(100, 3))
qqnorm(rchisq(100, 3))
hist(rchisq(100, 3))
x = scale(rchisq(100, 3))
x
qqplot(x)
hist(x)
qqnorm(x)
women = read.table('muscle.txt')
names(women) = c('muscle', 'age')
simple = lm(muscle ~ age, data=women)
plot(simple)
?predict.lm
ss = summary(simple)
ss
ss$
str(ss)
ss
ss$coefficients
confint(simple)
ss$terms
confint(lm)
confint(simple)
confint(simple, '(Intercept)')
confint(simple, '(Intercept)', 99)
confint(simple, '(Intercept)', 0.99)
rnorm?
?rnorm
qt(0.99)
qt?
?qt
qt(0.005, 90)
ss
anova(simple)
qt(0.995, 58)
qnorm(0.995)
a = qt(0.995, 58)
simple$coefficients
ss
confint(simple, '(Intercept)', 0.99)
a
ss[1,2]
class(ss)
str(ss)
ss
str(ss)
anova(simple)
ss
coef(ss)
coef(ss)[1, 2]
coef(ss)[1, 2] * qt(0.995, 58)
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58)
confint(simple, 0.99)
?confint
confint(simple, level=0.99)
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58)
confint(simple, level=0.99)
confint(simple, level=0.99)[1, 2]
a = confint(simple, level=0.99)[1, 2]
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58)
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58) == a
a = confint(simple, level=0.99)[1, 2]
confint(simple, level=0.99)
dim(women)
ss
anova
anova(simple)
a = aanova(simple)
a
a = anova(simple)
a
class(a)
x = 1:100
y1 = x + runif(100)
y2 = x + rnorm(100)
mod = lm(x ~ y1 + y2)
mode
mod
anova(mod)
simple)
anova(simple)
anova(simple)['Residuals', 'Df']
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58) == a
simple$coefficients
ss$coefficients
alpha = 0.01
degfree = anova(simple)['Residuals', 'Df']
t99 = qt(alpha, df=degfree)
tstar = simple$coefficients[1] / ss$coefficients[1, 'Std. Error']
tstar
t99
b1 = simple$coefficients[2]
tstar = b1 / ss$coefficients[2, 'Std. Error']
tstar
quit()
a
alpha
qf(alpha, 1, n-2)
n = 60
qf(alpha, 1, n-2)
?qf
mse
simple$residuals
simple$residuals ** 2
simple$residuals ** 2 / n
sum(simple$residuals ** 2) / n
quit()

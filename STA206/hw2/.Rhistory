hist(outcome)
source('~/dropbox/python/learn/blackjack.R')
install.packages('ggplot2')
source('~/dropbox/python/learn/blackjack.R')
?qplot
qplot(outcome)
?print
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
sum(outcome < 100) / length(outcome)
sum(outcome < -100) / length(outcome)
sum(outcome > 100) / length(outcome)
sum(outcome >= 100) / length(outcome)
mean(outcome)
# House edge: The ratio of the expected player loss to the initial wager.
house_edge_percent <- 0.5
house_edge <- house_edge_percent / 100
house_edge
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
odds
sum(odds)
source('~/dropbox/python/learn/blackjack.R')
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
source('~/dropbox/python/learn/blackjack.R')
qplot(outcome)
y <- seq(-pi, pi, 50)
y <- seq(-pi, pi, length=50)
x <- y
?outer
f = outer(x,y, function(x,y) cos(y)/(1+x^2))
?contour
contour(x,y,f)
contour(x,y,f, nlevels=45, add=T)
fa = (f-t(f))/2
?t
image(x,y,fa)
persp(x,y,fa)
persp(x,y,fa, theta = 30, phi=20)
?fix
fix(x)
test = function(x){}
test = function(x){
print('hey there')
sin(x) + 291
}
test
fix(test)
# This script creates plots illustrating the curse of dimensionality
# Choose points, randomly distributed
n <- 3000  # number of points
p <- 50  # number of dimensions
x <- matrix(runif(n*p), ncol=p)
Fringe <- function(z){
# Determine if z lies within 0.05 distance from the boundary
# z is a vector of length p
any(abs(z - 0.5) > 0.45)
}
result <- apply(x, 1, Fringe)
plot(x[,1:2])
points(x[,1][result], x[,2][result], col='red')
source('~/dropbox/python/learn/stat-learning/ch2/notes/dimension.R')
plot(x[,1:2])
points(x[,1][result], x[,2][result], col='red')
library(MASS)
library(ISLR)
attach(Boston)
lm.fit = lm(medv ~ lstat)
plot(lstat,medv)
abline(lm.fit)
abline(lm.fit, lwd=3)
abline(lm.fit, lwd=3, col='red')
plot(lstat,medv,col='red')
plot(lstat,medv,pch=20)
plot(lstat,medv,pch='+')
plot(1:20, 1:20, pch=1:20)
?rstudent
plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
?hatvalues
plot(hatvalues(lm.fit))
?which.max
which.max(hatvalues(lm.fit))
str(lm.fit)
?lm.fit
lm.fit
medv[375]
lstat[375]
plot(lstat, medv)
points(13.8, 27.97, cex=2, col='red')
points(37.97, 13.8, cex=2, col='red', pch=20)
install.packages('knirt')
install.packages('knitr')
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00225/Indian%20Liver%20Patient%20Dataset%20(ILPD).csv'
a <- read.csv(url)
a <- list(cat=1, dog=2)
a
names(a)
names(a) = c('toad', 'frog')
names(a)
mean
knn
kmeans
?classe
?class
x <- 10
x
class(x)
class(x) <- 'funstuff'
class(x)
plot.funstuff <- function(x) hist(1:10)
plot.funstuff(x)
plot(x)
plot(x)
mean(x)
print.funstuff <- function(x) print('rock and roll dude')
print(x)
x
x + 5
x > 10
setwd('~/junkyard/STA206/hw2')
women = read.table('muscle.txt')
names(women) = c('age', 'muscle')
library(ggplot2)
?qplot
qplot(women$muscle)
par(mfrow=2)
hist(women$age, main = 'age')
hist(women$muscle, main = 'muscle')
par(mfrow=c(2, 1))
hist(women$age, main = 'age')
hist(women$muscle, main = 'muscle')
par(mfrow=c(1, 2))
hist(women$age, main = 'age')
hist(women$muscle, main = 'muscle')
?hist
par(mfrow=c(1, 2))
hist(women$age, xlab = 'age')
hist(women$muscle, xlab = 'muscle')
par(mfrow=c(1, 2))
hist(women$age, main = 'age', xlab='')
hist(women$muscle, main = 'muscle', xlab='')
?hist
par(mfrow=c(1, 2))
hist(women$age, xlab = 'age', main = '')
hist(women$muscle, xlab = 'muscle', main = '')
max(women)
source('~/.active-rstudio-document', echo=TRUE)
plot(women$age, women$muscle)
?plot
plot(women$age, women$muscle, xlab = 'age', ylab = 'muscle')
?par
simple = lm(muscle ~ age, data=women)
simple
summary(simple)
anova(simple)
coef(simple)
summary(simple)
anova(simple)
anova(women)
?sprintf
sprintf('%.3f and then', pi)
coef(simple)
simple = lm(muscle ~ age, data=women)
coef(simple)
summary(simple)
str(simple)
str(simple)
s = summary(simple)
s
str(s)
simple$coefficients
simple_summary = summary(simple)
simple_summary$coefficients[, 'Std. Error']
a = anova(simple)
a['Residuals', c('Df', 'Mean Sq')]
library(plyr)
?splat
sprintf('% and %', 1 2)
sprintf('% and %', 1, 2)
sprintf('%f and %f', 1, 2)
sprintf('%f and %f', c(1, 2))
splat(sprintf)('%f and %f', c(1, 2))
a
simple$coefficients
simple$coefficients[0]
simple$coefficients[1]
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
simple$coefficients$age)
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
simple$coefficients['age']
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
simple$coefficients['age'])
sprintf('muscle = %.2f + %.2f * age', simple$coefficients[1],
simple$coefficients['age'])
simple$coefficients['(Intercept)']
scatter()
abline(simple)
scatter = function(){
plot(women$age, women$muscle, xlab = 'age', ylab = 'muscle')
}
scatter()
scatter()
abline(simple)
simple$fitted.values[c(6, 16)]
simple$residuals[c(6, 16)]
plot.lm
plot(simple)
plot.lm(simple, which = 1)
plot.lm(simple, which = c(1, 2))
plot.lm(simple, which = c(1, 2))
plot.lm(simple, which = 2)
par(mfrow=c(1, 2))
plot.lm(simple, which=1)
plot.lm(simple, which=2)
hist(simple$residuals)
par(mfrow=c(1, 2))
plot.lm(simple, which=1)
plot.lm(simple, which=2)
plot(lm(1:99 ~ 1:99))
plot(lm(y ~ x, data=data.frame(1:99)))
df = data.frame(y=1:99, x=1:99 + rchisq(99, df=2))
plot.lm(df)
plot(lm(y ~ x, df))
plot.lm(df, which=2)
plot(lm(y ~ x, df), which=2)
hist(rchisq(99, 2))
qqplot(3 * rnorm(100))
?qqplot
qqnorm(3 * rnorm(100))
qqnorm(1.5 * rnorm(100))
par(mfrow=c(1,1))
qqnorm(1.5 * rnorm(100))
qqnorm(2 * rnorm(100))
qqline()
qqnorm(2 * rnorm(100))
qqnorm(chisq(100, 3))
qqnorm(rchisq(100, 3))
hist(rchisq(100, 3))
x = scale(rchisq(100, 3))
x
qqplot(x)
hist(x)
qqnorm(x)
women = read.table('muscle.txt')
names(women) = c('muscle', 'age')
simple = lm(muscle ~ age, data=women)
plot(simple)
?predict.lm
ss = summary(simple)
ss
ss$
str(ss)
ss
ss$coefficients
confint(simple)
ss$terms
confint(lm)
confint(simple)
confint(simple, '(Intercept)')
confint(simple, '(Intercept)', 99)
confint(simple, '(Intercept)', 0.99)
rnorm?
?rnorm
qt(0.99)
qt?
?qt
qt(0.005, 90)
ss
anova(simple)
qt(0.995, 58)
qnorm(0.995)
a = qt(0.995, 58)
simple$coefficients
ss
confint(simple, '(Intercept)', 0.99)
a
ss[1,2]
class(ss)
str(ss)
ss
str(ss)
anova(simple)
ss
coef(ss)
coef(ss)[1, 2]
coef(ss)[1, 2] * qt(0.995, 58)
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58)
confint(simple, 0.99)
?confint
confint(simple, level=0.99)
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58)
confint(simple, level=0.99)
confint(simple, level=0.99)[1, 2]
a = confint(simple, level=0.99)[1, 2]
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58)
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58) == a
a = confint(simple, level=0.99)[1, 2]
confint(simple, level=0.99)
dim(women)
ss
anova
anova(simple)
a = aanova(simple)
a
a = anova(simple)
a
class(a)
x = 1:100
y1 = x + runif(100)
y2 = x + rnorm(100)
mod = lm(x ~ y1 + y2)
mode
mod
anova(mod)
simple)
anova(simple)
anova(simple)['Residuals', 'Df']
simple$coefficients[1] + coef(ss)[1, 2] * qt(0.995, 58) == a
simple$coefficients
ss$coefficients
alpha = 0.01
degfree = anova(simple)['Residuals', 'Df']
t99 = qt(alpha, df=degfree)
tstar = simple$coefficients[1] / ss$coefficients[1, 'Std. Error']
tstar
t99
b1 = simple$coefficients[2]
tstar = b1 / ss$coefficients[2, 'Std. Error']
tstar
quit()
a
alpha
qf(alpha, 1, n-2)
n = 60
qf(alpha, 1, n-2)
?qf
mse
simple$residuals
simple$residuals ** 2
simple$residuals ** 2 / n
sum(simple$residuals ** 2) / n
quit()
source('hw2_second.R')
X
?matrix
model.matrix(1:10)
?model.matrix
?matrix
source('hw2_second.R')
X
source('hw2_second.R')
?print
source('hw2_second.R')
source('hw2_second.R')
source('hw2_second.R')
source('hw2_second.R')
t(X)
t(X) %*% x
t(X) %*% X
r
source('hw2_second.R')
r['X']
r['a'] = 23
r
source('hw2_second.R')
source('hw2_second.R')
xtx
source('hw2_second.R')
source('hw2_second.R')
globalVariables()
ls()
?ls
?.GlobalEnv
.GlobalEnv)
.GlobalEnv()
as.list(.GlobalEnv)
quit()
summary(simple)
?qt
confint(simple)
predict(simple, data.frame(age=60))
predict(simple, data.frame(age=60), interval='prediction')
predict(simple, data.frame('age'=60), interval='prediction')
simple
predict(simple, 60)
p60
p60 = predict(simple, data.frame(age=60), se.fit=TRUE, interval='prediction', level=0.95)
p60
W
W = sqrt(2 * qf(0.95, 2, df))
W = sqrt(2 * qf(0.95, 2, 58))
W
se60 = p60$se.fit
se60
c(fit60 - W * se60, fit60 + W * se60)
fit60 = p60$fit[1]
c(fit60 - W * se60, fit60 + W * se60)
f99 = qt(0.99, 1, n-2)
f99
f99 = qf(0.99, 1, n-2)
f99
summary(simple)
s = summary(simple)
s
s$r.squared
s$adj.r.squared
s
library(Matrix)
x
x = as.matrix(x, nrow=10)
x
dim(x)
x = matrix(x, nrow=10)
x
clear
rankMatrix(x)
rankMatrix(x)[1]
diag(10)
diag(10) - x
x - diag(10)
source('hw2_5.R')
dim(X)
X
source('hw2_5.R')
X
dim(H)
source('hw2_5.R')
r
rankMatrix(H)
X
nrow(X)
XtX_inverse
diag(XtX_inverse))
sqrt(diag(XtX_inverse))
sqrt(diag(XtX_inverse)[2, 3]
XtX_inverse[2, 3]
source('hw2_5.R')
source('hw2_5.R')
I- H)
(I- H)[1, 1]
MSE
SSE
df_SSE
source('hw2_5.R')
MSE
X
X[, 4] = 1:5
X
source('hw2_5.R')
X
X[, 2] * X[, 3]
0.18 * 0.49
source('hw2_5.R')
rankMatrix(H)
rankMatrix(I-H)
source('hw2_5.R')
source('hw2_5.R')
r
source('hw2_5.R')
source('hw2_5.R')
SSTO
source('hw2_5.R')
SSTO
SSE
SSE2
source('hw2_5.R')
quit()
a <- matrix(rep(1, 4), nrow=2)
a
b = matrix(c(1, 2, 1, 2), nrow=2)
b
b = matrix(c(1, 1, 2, 2), nrow=2)
b
b = matrix(c(1, 2, 2, 2), nrow=2)
b
b = matrix(c(1, 2, 2, 1), nrow=2)
b
a %*% b
b %*% a
a = matrix(rep(1, 9), nrow=3)
a
b = matrix(c(1, 2, 3, 2, 4, 2.5, 3, 2.5, 5), nrow=3)
b
a %*% b
b %*% a
b %*% a - a %*% b
H
H ** 2
H ^ 2
2^(-1)
H^(-1)
Jn = matrix(rep(1, 25), nrow-5)
Jn = matrix(rep(1, 25), nrow=5)
Jn
Jn %*% H
H %*% Jn
colSums(H)
rowSums(H)
f99
qf(0.99, 1, 58)
quit()
